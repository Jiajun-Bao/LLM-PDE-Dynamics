{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook prepares the data for the subsequent notebook `10-Step-Analyze-Chebyshev.ipynb`, which generates the figure illustrating the multi-step rollouts on non-uniform grids, as described in Supplementary Material Section 8.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "num_devices = torch.cuda.device_count()\n",
    "print(\"Number of visible GPUs:\", num_devices)\n",
    "\n",
    "for i in range(num_devices):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "current_device = torch.cuda.current_device()\n",
    "print(\"Current device index:\", current_device)\n",
    "print(\"Current device name:\", torch.cuda.get_device_name(current_device))\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from data_processing import (\n",
    "    SimpleSerializerSettings, scale_2d_array, unscale_2d_array,\n",
    "    serialize_2d_integers, deserialize_2d_integers\n",
    ")\n",
    "\n",
    "from allen_cahn_equation_Chebyshev import (\n",
    "    compute_exact_solution_random_ic_vary_Nx,\n",
    "    visualize_spline_ic,\n",
    "    plot_both_grids\n",
    ")\n",
    "\n",
    "from llama_utils import load_model_and_tokenizer, llm_multi_predictions\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B\"\n",
    "# MODEL_NAME = \"meta-llama/Llama-3.2-3B\"\n",
    "# MODEL_NAME = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Demonstrating the process of generating and visualizing a random initial condition\n",
    "L = 2\n",
    "Nx = 14\n",
    "init_cond_random = np.random.uniform(-0.5, 0.5, size=Nx)\n",
    "fig, cs = visualize_spline_ic(L, Nx, init_cond_random)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Example: Demonstrating how to resample spatial points from an underlying random initial condition\n",
    "Nx_original = Nx\n",
    "Nx_new = 14\n",
    "fig, cs, init_cond_random_new = plot_both_grids(L, Nx_original, Nx_new, init_cond_random)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for the Allen-Cahn equation\n",
    "L = 2       # Length of the spatial domain\n",
    "k = 0.001   # Thermal diffusivity\n",
    "T = 0.5     # Total simulation time\n",
    "Nt = 25     # Number of time steps\n",
    "dt = T/Nt\n",
    "Nx = 14     # Number of spatial steps (excluding boundary points)\n",
    "dx = L/(Nx+1)\n",
    "settings = SimpleSerializerSettings(space_sep=\",\", time_sep=\";\")\n",
    "input_time_steps = 16\n",
    "number_of_future_predictions = 10\n",
    "n_ics = 20      \n",
    "n_runs_per_ic = 20\n",
    "\n",
    "# Generate all random initial conditions and spline objects\n",
    "stored_initial_conditions = []\n",
    "stored_spline_objects = []\n",
    "for ic_seed in range(n_ics):\n",
    "    random.seed(ic_seed)\n",
    "    np.random.seed(ic_seed)\n",
    "    torch.manual_seed(ic_seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(ic_seed)\n",
    "    init_cond_random = np.random.uniform(-0.5, 0.5, size=Nx)\n",
    "    stored_initial_conditions.append(init_cond_random.copy())\n",
    "    fig, cs = visualize_spline_ic(L, Nx, init_cond_random)\n",
    "    plt.close(fig)\n",
    "    stored_spline_objects.append(cs)\n",
    "\n",
    "stored_initial_conditions_array = np.array(stored_initial_conditions)\n",
    "all_llm_max_diffs = []\n",
    "all_llm_rmses = []\n",
    "\n",
    "for ic_seed in tqdm(range(n_ics)):\n",
    "    # Use the stored initial condition and spline\n",
    "    init_cond_random = stored_initial_conditions[ic_seed]\n",
    "    cs = stored_spline_objects[ic_seed]\n",
    "    # Compute exact solution for this initial condition on Chebyshev grid\n",
    "    u_exact_cheb = compute_exact_solution_random_ic_vary_Nx(L, k, T, Nx, Nt, spline_obj=cs, use_chebyshev=True)\n",
    "    u_exact_scaled_cheb, vmin_exact_cheb, vmax_exact_cheb = scale_2d_array(u_exact_cheb)\n",
    "    u_exact_serialized_cheb = serialize_2d_integers(u_exact_scaled_cheb, settings)\n",
    "    # Run LLM prediction for this initial condition\n",
    "    llm_max_diffs_cheb, llm_rmses_cheb, _, _, _  = llm_multi_predictions(\n",
    "        full_serialized_data=u_exact_serialized_cheb,\n",
    "        input_time_steps=input_time_steps,\n",
    "        number_of_future_predictions=number_of_future_predictions,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        Nx=Nx,\n",
    "        settings=settings,\n",
    "        vmin=vmin_exact_cheb,\n",
    "        vmax=vmax_exact_cheb,\n",
    "        n_seeds=n_runs_per_ic\n",
    "    )\n",
    "\n",
    "    all_llm_max_diffs.append(llm_max_diffs_cheb)\n",
    "    all_llm_rmses.append(llm_rmses_cheb)\n",
    "\n",
    "# Compute quant floor\n",
    "all_baseline_max_errors_per_step = []\n",
    "all_baseline_rmse_errors_per_step = []\n",
    "\n",
    "for ic_seed in range(n_ics):\n",
    "    # Use the stored initial condition and spline\n",
    "    init_cond_random = stored_initial_conditions[ic_seed]\n",
    "    cs = stored_spline_objects[ic_seed]\n",
    "    # Compute exact solution for this initial condition on Chebyshev grid\n",
    "    u_exact_cheb = compute_exact_solution_random_ic_vary_Nx(L, k, T, Nx, Nt, spline_obj=cs, use_chebyshev=True)\n",
    "    # Quantization pipeline\n",
    "    u_exact_scaled_cheb, vmin_exact_cheb, vmax_exact_cheb = scale_2d_array(u_exact_cheb)\n",
    "    u_exact_serialized_cheb = serialize_2d_integers(u_exact_scaled_cheb, settings)\n",
    "    u_exact_parsed_cheb = deserialize_2d_integers(u_exact_serialized_cheb, settings)\n",
    "    u_exact_unscaled_cheb = unscale_2d_array(u_exact_parsed_cheb, vmin_exact_cheb, vmax_exact_cheb)\n",
    "    # Compute baseline errors at each time step for this seed\n",
    "    seed_max_errors_per_step = []\n",
    "    seed_rmse_errors_per_step = []\n",
    "    \n",
    "    for t in range(u_exact_cheb.shape[0]):\n",
    "            max_err_t  = np.max(np.abs(u_exact_cheb[t] - u_exact_unscaled_cheb[t]))\n",
    "            rmse_err_t = np.sqrt(np.mean((u_exact_cheb[t] - u_exact_unscaled_cheb[t])**2))\n",
    "            seed_max_errors_per_step.append(max_err_t)\n",
    "            seed_rmse_errors_per_step.append(rmse_err_t)\n",
    "\n",
    "    all_baseline_max_errors_per_step.append(seed_max_errors_per_step)\n",
    "    all_baseline_rmse_errors_per_step.append(seed_rmse_errors_per_step)\n",
    "\n",
    "all_baseline_max_errors_per_step  = np.array(all_baseline_max_errors_per_step)\n",
    "all_baseline_rmse_errors_per_step = np.array(all_baseline_rmse_errors_per_step)\n",
    "\n",
    "# Compute averages for per-step quantization errors\n",
    "avg_baseline_max_errors_per_step = np.mean(all_baseline_max_errors_per_step, axis=0)\n",
    "avg_baseline_rmse_errors_per_step = np.mean(all_baseline_rmse_errors_per_step, axis=0)\n",
    "# Extract the prediction time steps (from step 16 onwards)\n",
    "avg_baseline_max_errors_prediction = avg_baseline_max_errors_per_step[input_time_steps:]\n",
    "avg_baseline_rmse_errors_prediction = avg_baseline_rmse_errors_per_step[input_time_steps:]\n",
    "# Compute averages and standard deviations for LLM results\n",
    "avg_llm_max_diffs_cheb = np.mean(all_llm_max_diffs, axis=0)\n",
    "avg_llm_rmses_cheb = np.mean(all_llm_rmses, axis=0)\n",
    "std_llm_max_diffs_cheb = np.std(all_llm_max_diffs, axis=0, ddof=1)\n",
    "std_llm_rmses_cheb = np.std(all_llm_rmses, axis=0, ddof=1)\n",
    "\n",
    "def log_ci(mean, std, n, tcrit):\n",
    "    \"\"\"\n",
    "    95% CI for log10 axis\n",
    "    mean : arithmetic mean of the n samples\n",
    "    std : sample std of the n samples\n",
    "    n : number of samples\n",
    "    tcrit: two-sided t critical value\n",
    "    \"\"\"\n",
    "    se = std / np.sqrt(n)  # SE in linear space\n",
    "    se_log = se / (mean * np.log(10))  # delta-method SE in log space\n",
    "    mean_log = np.log10(mean)\n",
    "    delta_log = tcrit * se_log\n",
    "    return 10**(mean_log - delta_log), 10**(mean_log + delta_log)\n",
    "\n",
    "# Calculate confidence intervals\n",
    "t_critical = stats.t.ppf(0.975, n_ics - 1)  # 95% CI\n",
    "ci_lower_max_diffs_8B_cheb = []\n",
    "ci_upper_max_diffs_8B_cheb = []\n",
    "ci_lower_rmses_8B_cheb = []\n",
    "ci_upper_rmses_8B_cheb = []\n",
    "\n",
    "for mean, std in zip(avg_llm_max_diffs_cheb, std_llm_max_diffs_cheb):\n",
    "    lower, upper = log_ci(mean, std, n_ics, t_critical)\n",
    "    ci_lower_max_diffs_8B_cheb.append(lower)\n",
    "    ci_upper_max_diffs_8B_cheb.append(upper)\n",
    "\n",
    "for mean, std in zip(avg_llm_rmses_cheb, std_llm_rmses_cheb):\n",
    "    lower, upper = log_ci(mean, std, n_ics, t_critical)\n",
    "    ci_lower_rmses_8B_cheb.append(lower)\n",
    "    ci_upper_rmses_8B_cheb.append(upper)\n",
    "\n",
    "np.savez_compressed(\n",
    "    \"8B_10_step_chebyshev.npz\",\n",
    "    # Averaged LLM metrics on Chebyshev grid\n",
    "    llm_max_diffs_8B_cheb=avg_llm_max_diffs_cheb,\n",
    "    llm_rmses_8B_cheb=avg_llm_rmses_cheb,\n",
    "    std_max_diffs_8B_cheb=std_llm_max_diffs_cheb,\n",
    "    std_rmses_8B_cheb=std_llm_rmses_cheb,\n",
    "    # LLM confidence intervals\n",
    "    ci_lower_max_diffs_8B_cheb=ci_lower_max_diffs_8B_cheb,\n",
    "    ci_upper_max_diffs_8B_cheb=ci_upper_max_diffs_8B_cheb,\n",
    "    ci_lower_rmses_8B_cheb=ci_lower_rmses_8B_cheb,\n",
    "    ci_upper_rmses_8B_cheb=ci_upper_rmses_8B_cheb,\n",
    "    # Raw results for all initial conditions\n",
    "    all_llm_max_diffs=all_llm_max_diffs,\n",
    "    all_llm_rmses=all_llm_rmses,\n",
    "    # Quant Floor\n",
    "    avg_baseline_max_errors_prediction=avg_baseline_max_errors_prediction,\n",
    "    avg_baseline_rmse_errors_prediction=avg_baseline_rmse_errors_prediction,\n",
    "    # Store the initial conditions and grid info\n",
    "    stored_initial_conditions=stored_initial_conditions_array,\n",
    "    use_chebyshev=True,\n",
    "    Nx=Nx,\n",
    "    Nt=Nt,\n",
    "    L=L,\n",
    "    T=T,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "smollm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4bca38f991eb477fb6f6448ed40b7953": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f282a01a1fa94fd3841fa84b0bf85801",
      "placeholder": "​",
      "style": "IPY_MODEL_bfdb859e858e42869e6da9b1482a5702",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "79d7edd2ec684e25b3674d375812e5fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82fd26e315b6460ab439920956ecfc4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d598e552e3e4f3f9ffd47c953554ad0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79d7edd2ec684e25b3674d375812e5fc",
      "placeholder": "​",
      "style": "IPY_MODEL_b9ca4f266f0247a3aca54430f78c7bf4",
      "value": " 2/2 [00:04&lt;00:00,  2.25s/it]"
     }
    },
    "b9ca4f266f0247a3aca54430f78c7bf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be3db56ffe3047a6ab8493d65d18f5c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfdb859e858e42869e6da9b1482a5702": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0dd1da9791a4911932193befbfd4dd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e8bbace417ee4d74ae8e9fdcaf023b44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be3db56ffe3047a6ab8493d65d18f5c6",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e0dd1da9791a4911932193befbfd4dd0",
      "value": 2
     }
    },
    "f282a01a1fa94fd3841fa84b0bf85801": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd21f3afeb514a51a73822346535fdec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4bca38f991eb477fb6f6448ed40b7953",
       "IPY_MODEL_e8bbace417ee4d74ae8e9fdcaf023b44",
       "IPY_MODEL_8d598e552e3e4f3f9ffd47c953554ad0"
      ],
      "layout": "IPY_MODEL_82fd26e315b6460ab439920956ecfc4b"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
